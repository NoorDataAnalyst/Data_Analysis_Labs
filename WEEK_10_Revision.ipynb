{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "0403ec98",
      "metadata": {
        "id": "0403ec98"
      },
      "source": [
        "\n",
        "# Setup: Import Libraries and Suppress Warnings\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import sqlite3\n",
        "import warnings\n",
        "\n",
        "# Suppress all warnings for cleaner output\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "# You might need to download the chinook.db and student-mat/por.csv files if not in your environment.\n",
        "# For Google Colab, you might upload them or download via specific links.\n",
        "# Example for Colab if files are on GitHub (adjust URLs as needed):\n",
        "# !wget https://raw.githubusercontent.com/lerocha/chinook-database/master/ChinookDatabase/DataSources/Chinook_Sqlite.sqlite -O chinook.db\n",
        "# !wget https://raw.githubusercontent.com/gabrielaproenca/Student-Performance-Data-Set/master/student-mat.csv\n",
        "# !wget https://raw.githubusercontent.com/gabrielaproenca/Student-Performance-Data-Set/master/student-por.csv\n",
        "# !wget https://raw.githubusercontent.com/IBM/telco-customer-churn-extra-data/master/WA_Fn-UseC_-Telco-Customer-Churn.csv\n",
        "\n",
        "# Global dataframes that will be used across parts\n",
        "titanic_df = None\n",
        "telco_df = None\n",
        "conn = None # For SQLite connection\n",
        "merged_students_df = None\n"
      ],
      "metadata": {
        "id": "lSNiqVspSn4D"
      },
      "id": "lSNiqVspSn4D",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "2satExaTSA1V"
      },
      "id": "2satExaTSA1V",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a9bb22cb"
      },
      "source": [
        "\n",
        "## Part 1 Solutions: Data Loading, Inspection, and Cleaning\n",
        "\n",
        "### Task 1.1 Solution: Load and Initial Inspection (Titanic Dataset)\n",
        "\n"
      ],
      "id": "a9bb22cb"
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Load the Titanic dataset\n",
        "\n",
        "titanic_df = pd.read_csv('https://raw.githubusercontent.com/datasciencedojo/datasets/master/titanic.csv')\n",
        "\n"
      ],
      "metadata": {
        "id": "UCe6Qj4_SG91"
      },
      "id": "UCe6Qj4_SG91",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Display the first 5 rows\n",
        "# Display the first 5 rows\n",
        "print(\"### First 5 rows of Titanic DataFrame:\")\n",
        "print(titanic_df.head())\n",
        "print(\"\\n\" + \"#\" * 50 + \"\\n\")\n",
        " # Separator for clarity\n",
        " # Separator for clarity\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Qz5a8OYvSbtV",
        "outputId": "39fe83ef-cac9-42a2-f8ac-1aea26341cf8"
      },
      "id": "Qz5a8OYvSbtV",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "### First 5 rows of Titanic DataFrame:\n",
            "   PassengerId  Survived  Pclass  \\\n",
            "0            1         0       3   \n",
            "1            2         1       1   \n",
            "2            3         1       3   \n",
            "3            4         1       1   \n",
            "4            5         0       3   \n",
            "\n",
            "                                                Name     Sex   Age  SibSp  \\\n",
            "0                            Braund, Mr. Owen Harris    male  22.0      1   \n",
            "1  Cumings, Mrs. John Bradley (Florence Briggs Th...  female  38.0      1   \n",
            "2                             Heikkinen, Miss. Laina  female  26.0      0   \n",
            "3       Futrelle, Mrs. Jacques Heath (Lily May Peel)  female  35.0      1   \n",
            "4                           Allen, Mr. William Henry    male  35.0      0   \n",
            "\n",
            "   Parch            Ticket     Fare Cabin Embarked  \n",
            "0      0         A/5 21171   7.2500   NaN        S  \n",
            "1      0          PC 17599  71.2833   C85        C  \n",
            "2      0  STON/O2. 3101282   7.9250   NaN        S  \n",
            "3      0            113803  53.1000  C123        S  \n",
            "4      0            373450   8.0500   NaN        S  \n",
            "\n",
            "##################################################\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Get a concise summary of the DataFrame\n",
        "print(\"### DataFrame Information:\")\n",
        "titanic_df.info()\n",
        "print(\" \" + \"#\" * 50 + \" \")\n",
        "\n",
        "# Display descriptive statistics for numerical columns\n",
        "# Get a concise summary of the DataFrame\n",
        "print(\"### DataFrame Information:\")\n",
        "titanic_df.info()\n",
        "print(\" \" + \"#\" * 50 + \" \")\n",
        "\n",
        "# Display descriptive statistics for numerical columns\n",
        "# Get a concise summary of the DataFrame\n",
        "print(\"### DataFrame Information:\")\n",
        "titanic_df.info()\n",
        "print(\" \" + \"#\" * 50 + \" \")\n",
        "\n",
        "# Display descriptive statistics for numerical columns\n",
        "# Get a concise summary of the DataFrame\n",
        "print(\"### DataFrame Information:\")\n",
        "titanic_df.info()\n",
        "print(\" \" + \"#\" * 50 + \" \")\n",
        "\n",
        "# Display descriptive statistics for numerical columns\n",
        "print(\"### Descriptive Statistics for Numerical Columns:\")\n",
        "print(titanic_df.describe())\n",
        "print(\"\\n\" + \"#\" * 50 + \"\\n\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PNe3LgU3SK6t",
        "outputId": "bf2b7307-f3c4-427c-dc98-246a37ebb2b7"
      },
      "id": "PNe3LgU3SK6t",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "### DataFrame Information:\n",
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 891 entries, 0 to 890\n",
            "Data columns (total 12 columns):\n",
            " #   Column       Non-Null Count  Dtype  \n",
            "---  ------       --------------  -----  \n",
            " 0   PassengerId  891 non-null    int64  \n",
            " 1   Survived     891 non-null    int64  \n",
            " 2   Pclass       891 non-null    int64  \n",
            " 3   Name         891 non-null    object \n",
            " 4   Sex          891 non-null    object \n",
            " 5   Age          714 non-null    float64\n",
            " 6   SibSp        891 non-null    int64  \n",
            " 7   Parch        891 non-null    int64  \n",
            " 8   Ticket       891 non-null    object \n",
            " 9   Fare         891 non-null    float64\n",
            " 10  Cabin        204 non-null    object \n",
            " 11  Embarked     889 non-null    object \n",
            "dtypes: float64(2), int64(5), object(5)\n",
            "memory usage: 83.7+ KB\n",
            " ################################################## \n",
            "### DataFrame Information:\n",
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 891 entries, 0 to 890\n",
            "Data columns (total 12 columns):\n",
            " #   Column       Non-Null Count  Dtype  \n",
            "---  ------       --------------  -----  \n",
            " 0   PassengerId  891 non-null    int64  \n",
            " 1   Survived     891 non-null    int64  \n",
            " 2   Pclass       891 non-null    int64  \n",
            " 3   Name         891 non-null    object \n",
            " 4   Sex          891 non-null    object \n",
            " 5   Age          714 non-null    float64\n",
            " 6   SibSp        891 non-null    int64  \n",
            " 7   Parch        891 non-null    int64  \n",
            " 8   Ticket       891 non-null    object \n",
            " 9   Fare         891 non-null    float64\n",
            " 10  Cabin        204 non-null    object \n",
            " 11  Embarked     889 non-null    object \n",
            "dtypes: float64(2), int64(5), object(5)\n",
            "memory usage: 83.7+ KB\n",
            " ################################################## \n",
            "### DataFrame Information:\n",
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 891 entries, 0 to 890\n",
            "Data columns (total 12 columns):\n",
            " #   Column       Non-Null Count  Dtype  \n",
            "---  ------       --------------  -----  \n",
            " 0   PassengerId  891 non-null    int64  \n",
            " 1   Survived     891 non-null    int64  \n",
            " 2   Pclass       891 non-null    int64  \n",
            " 3   Name         891 non-null    object \n",
            " 4   Sex          891 non-null    object \n",
            " 5   Age          714 non-null    float64\n",
            " 6   SibSp        891 non-null    int64  \n",
            " 7   Parch        891 non-null    int64  \n",
            " 8   Ticket       891 non-null    object \n",
            " 9   Fare         891 non-null    float64\n",
            " 10  Cabin        204 non-null    object \n",
            " 11  Embarked     889 non-null    object \n",
            "dtypes: float64(2), int64(5), object(5)\n",
            "memory usage: 83.7+ KB\n",
            " ################################################## \n",
            "### DataFrame Information:\n",
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 891 entries, 0 to 890\n",
            "Data columns (total 12 columns):\n",
            " #   Column       Non-Null Count  Dtype  \n",
            "---  ------       --------------  -----  \n",
            " 0   PassengerId  891 non-null    int64  \n",
            " 1   Survived     891 non-null    int64  \n",
            " 2   Pclass       891 non-null    int64  \n",
            " 3   Name         891 non-null    object \n",
            " 4   Sex          891 non-null    object \n",
            " 5   Age          714 non-null    float64\n",
            " 6   SibSp        891 non-null    int64  \n",
            " 7   Parch        891 non-null    int64  \n",
            " 8   Ticket       891 non-null    object \n",
            " 9   Fare         891 non-null    float64\n",
            " 10  Cabin        204 non-null    object \n",
            " 11  Embarked     889 non-null    object \n",
            "dtypes: float64(2), int64(5), object(5)\n",
            "memory usage: 83.7+ KB\n",
            " ################################################## \n",
            "### Descriptive Statistics for Numerical Columns:\n",
            "       PassengerId    Survived      Pclass         Age       SibSp  \\\n",
            "count   891.000000  891.000000  891.000000  714.000000  891.000000   \n",
            "mean    446.000000    0.383838    2.308642   29.699118    0.523008   \n",
            "std     257.353842    0.486592    0.836071   14.526497    1.102743   \n",
            "min       1.000000    0.000000    1.000000    0.420000    0.000000   \n",
            "25%     223.500000    0.000000    2.000000   20.125000    0.000000   \n",
            "50%     446.000000    0.000000    3.000000   28.000000    0.000000   \n",
            "75%     668.500000    1.000000    3.000000   38.000000    1.000000   \n",
            "max     891.000000    1.000000    3.000000   80.000000    8.000000   \n",
            "\n",
            "            Parch        Fare  \n",
            "count  891.000000  891.000000  \n",
            "mean     0.381594   32.204208  \n",
            "std      0.806057   49.693429  \n",
            "min      0.000000    0.000000  \n",
            "25%      0.000000    7.910400  \n",
            "50%      0.000000   14.454200  \n",
            "75%      0.000000   31.000000  \n",
            "max      6.000000  512.329200  \n",
            "\n",
            "##################################################\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c97b79c0",
      "metadata": {
        "id": "c97b79c0"
      },
      "source": [
        "\n",
        "### Task 1.2 Solution: Handling Missing Values (Titanic Dataset)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Identify the number of missing values in each column\n",
        "print(\"### Missing Values Before Cleaning:\")\n",
        "print(titanic_df.isnull().sum())\n",
        "print(\" \" + \"#\" * 50 + \" \")\n",
        "# Separator for clarity\n",
        "\n",
        "# Determine the percentage of missing values for Age and Cabin columns\n",
        "missing_age_percent = (titanic_df['Age'].isnull().sum() / len(titanic_df)) * 100\n",
        "missing_cabin_percent = (titanic_df['Cabin'].isnull().sum() / len(titanic_df)) * 100\n",
        "# Identify the number of missing values in each column\n",
        "print(\"### Missing Values Before Cleaning:\")\n",
        "print(titanic_df.isnull().sum())\n",
        "print(\" \" + \"#\" * 50 + \" \")\n",
        "# Separator for clarity\n",
        "\n",
        "# Determine the percentage of missing values for Age and Cabin columns\n",
        "missing_age_percent = (titanic_df['Age'].isnull().sum() / len(titanic_df)) * 100\n",
        "missing_cabin_percent = (titanic_df['Cabin'].isnull().sum() / len(titanic_df)) * 100\n",
        "\n",
        "print(f\"Percentage of missing 'Age' values: {missing_age_percent:.2f}%\")\n",
        "print(f\"Percentage of missing 'Cabin' values: {missing_cabin_percent:.2f}%\")\n",
        "\n",
        "#This line of Python code uses an f-string (formatted string literal) to print a\n",
        "#message that includes a calculated percentage, formatted to two decimal places.\n",
        "\n",
        "\n",
        "#This is an f-string. Introduced in Python 3.6, f-strings provide a concise and\n",
        "#readable way to embed Python expressions inside string literals. The f prefix\n",
        "#before the opening quotation mark (\") indicates that it's an f-string.\n",
        "\n",
        "# {missing_age_percent:.2f}:\n",
        "# This is the core of the f-string's power: an expression placeholder.\n",
        "#:: This colon introduces the format specifier.\n",
        "#.2f: This is the format specifier itself:\n",
        "#.2: Specifies that the number should be displayed with two digits after the decimal point.\n",
        "#f: Indicates that the number should be formatted as a fixed-point number (i.e., a floating-point number in decimal format).\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "t37JVDsNc9rH",
        "outputId": "420c6ea8-1e3a-4e65-dd18-456f9d51e62e"
      },
      "id": "t37JVDsNc9rH",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "### Missing Values Before Cleaning:\n",
            "PassengerId      0\n",
            "Survived         0\n",
            "Pclass           0\n",
            "Name             0\n",
            "Sex              0\n",
            "Age            177\n",
            "SibSp            0\n",
            "Parch            0\n",
            "Ticket           0\n",
            "Fare             0\n",
            "Cabin          687\n",
            "Embarked         2\n",
            "dtype: int64\n",
            " ################################################## \n",
            "### Missing Values Before Cleaning:\n",
            "PassengerId      0\n",
            "Survived         0\n",
            "Pclass           0\n",
            "Name             0\n",
            "Sex              0\n",
            "Age            177\n",
            "SibSp            0\n",
            "Parch            0\n",
            "Ticket           0\n",
            "Fare             0\n",
            "Cabin          687\n",
            "Embarked         2\n",
            "dtype: int64\n",
            " ################################################## \n",
            "Percentage of missing 'Age' values: 19.87%\n",
            "Percentage of missing 'Cabin' values: 77.10%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Fill missing 'Age' values with the median age\n",
        "median_age = titanic_df['Age'].median()\n",
        "titanic_df['Age'].fillna(median_age, inplace=True)\n",
        "print(f\"Filled missing 'Age' values with median: {median_age}\")\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BI481eFjdQ_c",
        "outputId": "e396ffcd-a551-4dda-a6c7-339d8ba2edd6"
      },
      "id": "BI481eFjdQ_c",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Filled missing 'Age' values with median: 28.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Drop the 'Cabin' column due to a high percentage of missing values\n",
        "titanic_df.drop('Cabin', axis=1, inplace=True)\n",
        "print(\"Dropped 'Cabin' column.\")\n",
        "\n",
        "# Fill missing 'Embarked' values with the most frequent port\n",
        "most_frequent_embarked = titanic_df['Embarked'].mode()[0]\n",
        "titanic_df['Embarked'].fillna(most_frequent_embarked, inplace=True)\n",
        "print(f\"Filled missing 'Embarked' values with most frequent: {most_frequent_embarked}\")\n",
        "print(\" \" + \"#\" * 50 + \" \")\n",
        "\n",
        "# Verify that no missing values remain\n",
        "print(\"### Missing Values After Cleaning:\")\n",
        "print(titanic_df.isnull().sum())\n",
        "print(\" \" + \"#\" * 50 + \" \")\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cZoND4yAdGaF",
        "outputId": "34411c2b-92af-4fcc-a625-b525f45d351b"
      },
      "id": "cZoND4yAdGaF",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dropped 'Cabin' column.\n",
            "Filled missing 'Embarked' values with most frequent: S\n",
            " ################################################## \n",
            "### Missing Values After Cleaning:\n",
            "PassengerId    0\n",
            "Survived       0\n",
            "Pclass         0\n",
            "Name           0\n",
            "Sex            0\n",
            "Age            0\n",
            "SibSp          0\n",
            "Parch          0\n",
            "Ticket         0\n",
            "Fare           0\n",
            "Embarked       0\n",
            "dtype: int64\n",
            " ################################################## \n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d49d390d",
      "metadata": {
        "id": "d49d390d"
      },
      "source": [
        "\n",
        "### Task 1.3 Solution: Data Type Conversion & Basic Feature Engineering (Telco Customer Churn)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the Telco Customer Churn dataset\n",
        "telco_df = pd.read_csv('WA_Fn-UseC_-Telco-Customer-Churn.csv')\n",
        "\n",
        "print(\"### Initial Info for Telco DataFrame:\")\n",
        "telco_df.info()\n",
        "print(\" \" + \"❤COMSATS\" * 10 + \" \")\n",
        "\n",
        "# Inspect 'TotalCharges' data type and convert\n",
        "print(\"Unique values in 'TotalCharges' before conversion (first few):\", telco_df['TotalCharges'].unique()[:10])\n",
        "\n",
        "# Convert 'TotalCharges' to numeric, coercing errors to NaN\n",
        "telco_df['TotalCharges'] = pd.to_numeric(telco_df['TotalCharges'], errors='coerce')\n",
        "\n",
        "# Fill any NaNs created by conversion (e.g., from empty strings) with 0 or median\n",
        "telco_df['TotalCharges'].fillna(0, inplace=True)\n",
        "\n",
        "print(\" ### Info for Telco DataFrame after TotalCharges conversion:\")\n",
        "telco_df.info()\n",
        "print(\" \" + \"#\" * 50 + \" \")\n",
        "\n",
        "# Create a new column 'HasInternetService'\n",
        "telco_df['HasInternetService'] = telco_df['InternetService'].apply(lambda x: 1 if x in ['DSL', 'Fiber optic'] else 0)\n",
        "\n",
        "print(\" ### Head of Telco DataFrame with new 'HasInternetService' column:\")\n",
        "print(telco_df[['InternetService', 'HasInternetService']].head())\n",
        "print(\" \" + \"❤COMSATS\" * 10 + \" \")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wlq3u7Kre24l",
        "outputId": "bff46a55-0d2d-483c-e73f-8203c42265f5"
      },
      "id": "wlq3u7Kre24l",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "### Initial Info for Telco DataFrame:\n",
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 7043 entries, 0 to 7042\n",
            "Data columns (total 21 columns):\n",
            " #   Column            Non-Null Count  Dtype  \n",
            "---  ------            --------------  -----  \n",
            " 0   customerID        7043 non-null   object \n",
            " 1   gender            7043 non-null   object \n",
            " 2   SeniorCitizen     7043 non-null   int64  \n",
            " 3   Partner           7043 non-null   object \n",
            " 4   Dependents        7043 non-null   object \n",
            " 5   tenure            7043 non-null   int64  \n",
            " 6   PhoneService      7043 non-null   object \n",
            " 7   MultipleLines     7043 non-null   object \n",
            " 8   InternetService   7043 non-null   object \n",
            " 9   OnlineSecurity    7043 non-null   object \n",
            " 10  OnlineBackup      7043 non-null   object \n",
            " 11  DeviceProtection  7043 non-null   object \n",
            " 12  TechSupport       7043 non-null   object \n",
            " 13  StreamingTV       7043 non-null   object \n",
            " 14  StreamingMovies   7043 non-null   object \n",
            " 15  Contract          7043 non-null   object \n",
            " 16  PaperlessBilling  7043 non-null   object \n",
            " 17  PaymentMethod     7043 non-null   object \n",
            " 18  MonthlyCharges    7043 non-null   float64\n",
            " 19  TotalCharges      7043 non-null   object \n",
            " 20  Churn             7043 non-null   object \n",
            "dtypes: float64(1), int64(2), object(18)\n",
            "memory usage: 1.1+ MB\n",
            " ❤COMSATS❤COMSATS❤COMSATS❤COMSATS❤COMSATS❤COMSATS❤COMSATS❤COMSATS❤COMSATS❤COMSATS \n",
            "Unique values in 'TotalCharges' before conversion (first few): ['29.85' '1889.5' '108.15' '1840.75' '151.65' '820.5' '1949.4' '301.9'\n",
            " '3046.05' '3487.95']\n",
            " ### Info for Telco DataFrame after TotalCharges conversion:\n",
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 7043 entries, 0 to 7042\n",
            "Data columns (total 21 columns):\n",
            " #   Column            Non-Null Count  Dtype  \n",
            "---  ------            --------------  -----  \n",
            " 0   customerID        7043 non-null   object \n",
            " 1   gender            7043 non-null   object \n",
            " 2   SeniorCitizen     7043 non-null   int64  \n",
            " 3   Partner           7043 non-null   object \n",
            " 4   Dependents        7043 non-null   object \n",
            " 5   tenure            7043 non-null   int64  \n",
            " 6   PhoneService      7043 non-null   object \n",
            " 7   MultipleLines     7043 non-null   object \n",
            " 8   InternetService   7043 non-null   object \n",
            " 9   OnlineSecurity    7043 non-null   object \n",
            " 10  OnlineBackup      7043 non-null   object \n",
            " 11  DeviceProtection  7043 non-null   object \n",
            " 12  TechSupport       7043 non-null   object \n",
            " 13  StreamingTV       7043 non-null   object \n",
            " 14  StreamingMovies   7043 non-null   object \n",
            " 15  Contract          7043 non-null   object \n",
            " 16  PaperlessBilling  7043 non-null   object \n",
            " 17  PaymentMethod     7043 non-null   object \n",
            " 18  MonthlyCharges    7043 non-null   float64\n",
            " 19  TotalCharges      7043 non-null   float64\n",
            " 20  Churn             7043 non-null   object \n",
            "dtypes: float64(2), int64(2), object(17)\n",
            "memory usage: 1.1+ MB\n",
            " ################################################## \n",
            " ### Head of Telco DataFrame with new 'HasInternetService' column:\n",
            "  InternetService  HasInternetService\n",
            "0             DSL                   1\n",
            "1             DSL                   1\n",
            "2             DSL                   1\n",
            "3             DSL                   1\n",
            "4     Fiber optic                   1\n",
            " ❤COMSATS❤COMSATS❤COMSATS❤COMSATS❤COMSATS❤COMSATS❤COMSATS❤COMSATS❤COMSATS❤COMSATS \n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "id": "6eb0ae26",
      "metadata": {
        "id": "6eb0ae26"
      },
      "source": [
        "\n",
        "## Part 2 Solutions: SQL with Python\n",
        "\n",
        "### Task 2.1 Solution: Connect and Query\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Connect to the Chinook database\n",
        "#conn = sqlite3.connect('chinook.db')\n",
        "#cursor = conn.cursor()\n",
        "\n"
      ],
      "metadata": {
        "id": "Vr4wXGs9fdg0"
      },
      "id": "Vr4wXGs9fdg0",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!wget https://raw.githubusercontent.com/lerocha/chinook-database/master/ChinookDatabase/DataSources/Chinook_Sqlite.sqlite -O chinook.db\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-72dDGeuhDhA",
        "outputId": "ad3f4d7f-8c93-4e8e-dcd6-cd8848b6d6ac"
      },
      "id": "-72dDGeuhDhA",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2025-06-12 00:30:02--  https://raw.githubusercontent.com/lerocha/chinook-database/master/ChinookDatabase/DataSources/Chinook_Sqlite.sqlite\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 1067008 (1.0M) [application/octet-stream]\n",
            "Saving to: ‘chinook.db’\n",
            "\n",
            "chinook.db          100%[===================>]   1.02M  --.-KB/s    in 0.04s   \n",
            "\n",
            "2025-06-12 00:30:03 (23.4 MB/s) - ‘chinook.db’ saved [1067008/1067008]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# SQL Query to select employee first and last names\n",
        "sql_query_employees = \"SELECT FirstName, LastName FROM Employee;\"\n",
        "\n"
      ],
      "metadata": {
        "id": "nbMyavDOf9w9"
      },
      "id": "nbMyavDOf9w9",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cursor.execute(\"SELECT name FROM sqlite_master WHERE type='table';\")\n",
        "tables = cursor.fetchall()\n",
        "print(tables)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tXcCEQ2dhSI3",
        "outputId": "3cb78a42-df65-4490-e2e5-e30c9bf6a09a"
      },
      "id": "tXcCEQ2dhSI3",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[('Album',), ('Artist',), ('Customer',), ('Employee',), ('Genre',), ('Invoice',), ('InvoiceLine',), ('MediaType',), ('Playlist',), ('PlaylistTrack',), ('Track',)]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Execute the query\n",
        "cursor.execute(sql_query_employees)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FQCCN8WHgcoj",
        "outputId": "921ded3d-173a-42ba-e0cf-b50eda58295c"
      },
      "id": "FQCCN8WHgcoj",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<sqlite3.Cursor at 0x7ca1b64f53c0>"
            ]
          },
          "metadata": {},
          "execution_count": 52
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Fetch all results\n",
        "employee_results = cursor.fetchall()\n",
        "\n",
        "# Print the results\n",
        "print(\"### Employee First and Last Names:\")\n",
        "for row in employee_results:\n",
        "    print(row)\n",
        "print(\" \" + \"#\" * 50 + \" \")\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GuiefGENgKB9",
        "outputId": "831a1261-7ed4-4bae-bb90-abc8e72f987e"
      },
      "id": "GuiefGENgKB9",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "### Employee First and Last Names:\n",
            "('Andrew', 'Adams')\n",
            "('Nancy', 'Edwards')\n",
            "('Jane', 'Peacock')\n",
            "('Margaret', 'Park')\n",
            "('Steve', 'Johnson')\n",
            "('Michael', 'Mitchell')\n",
            "('Robert', 'King')\n",
            "('Laura', 'Callahan')\n",
            " ################################################## \n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##2.2 Data with SQL and Analyze with Pandas\n"
      ],
      "metadata": {
        "id": "1bGdhv3MLub3"
      },
      "id": "1bGdhv3MLub3"
    },
    {
      "cell_type": "code",
      "source": [
        "# Task 2.2 Solution: Aggregate Data with SQL and Analyze with Pandas\n",
        "# SQL Query to count customers per country\n",
        "sql_query_Customer_by_Country = \"SELECT Country, COUNT(CustomerId) AS NumberOfCustomers FROM Customer GROUP BY Country ORDER BY NumberOfCustomers DESC;\"\n",
        "\n",
        "# Load the results into a Pandas DataFrame using pd.read_sql_query\n",
        "customers_by_country_df = pd.read_sql_query(sql_query_Customer_by_Country, conn)\n",
        "\n",
        "print(\"### Customers by Country:\")\n",
        "print(customers_by_country_df)\n",
        "print(\"\\n\" + \"#\" * 50 + \"\\n\") # Separator for clarity\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "ear1dDF3LqOj",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b00c1547-de28-4ac4-d243-b1a31d36bf25"
      },
      "id": "ear1dDF3LqOj",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "### Customers by Country:\n",
            "           Country  NumberOfCustomers\n",
            "0              USA                 13\n",
            "1           Canada                  8\n",
            "2           France                  5\n",
            "3           Brazil                  5\n",
            "4          Germany                  4\n",
            "5   United Kingdom                  3\n",
            "6         Portugal                  2\n",
            "7            India                  2\n",
            "8   Czech Republic                  2\n",
            "9           Sweden                  1\n",
            "10           Spain                  1\n",
            "11          Poland                  1\n",
            "12          Norway                  1\n",
            "13     Netherlands                  1\n",
            "14           Italy                  1\n",
            "15         Ireland                  1\n",
            "16         Hungary                  1\n",
            "17         Finland                  1\n",
            "18         Denmark                  1\n",
            "19           Chile                  1\n",
            "20         Belgium                  1\n",
            "21         Austria                  1\n",
            "22       Australia                  1\n",
            "23       Argentina                  1\n",
            "\n",
            "##################################################\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Using Pandas, find the country with the most customers\n",
        "most_customers_country = customers_by_country_df.loc[customers_by_country_df['NumberOfCustomers'].idxmax()]\n",
        "\n",
        "print(\"### Country with the Most Customers:\")\n",
        "print(most_customers_country)\n",
        "print(\"\\n\" + \"#\" * 50 + \"\\n\") # Separator for clarity"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "A3r2WaH2jRaN",
        "outputId": "4a577613-0bd5-4cc2-fd5b-1c9f39c99713"
      },
      "id": "A3r2WaH2jRaN",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "### Country with the Most Customers:\n",
            "Country              USA\n",
            "NumberOfCustomers     13\n",
            "Name: 0, dtype: object\n",
            "\n",
            "##################################################\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Task 2.3 Solution: Joining Tables and Data Manipulation"
      ],
      "metadata": {
        "id": "7SxxRsjUL2bU"
      },
      "id": "7SxxRsjUL2bU"
    },
    {
      "cell_type": "code",
      "source": [
        "# Task 2.3 Solution: Joining Tables and Data Manipulation\n",
        "# SQL Query to join invoices and invoice_items\n",
        "sql_query_invoice_details = \"\"\"\n",
        "SELECT\n",
        "    i.Invoice,\n",
        "    i.BillingCountry,\n",
        "    i.Total,\n",
        "    ii.UnitPrice,\n",
        "    ii.Quantity\n",
        "FROM\n",
        "    invoices AS i\n",
        "INNER JOIN\n",
        "    invoice_items AS ii ON i.InvoiceId = ii.InvoiceId;\n",
        "\"\"\""
      ],
      "metadata": {
        "id": "9ZD57WhoL5HZ"
      },
      "id": "9ZD57WhoL5HZ",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the joined data into a Pandas DataFrame\n",
        "#invoice_details_df = pd.read_sql_query(sql_query_invoices, conn)\n",
        "invoice_item_df = pd.read_sql_query(sql_query_invoice_details, conn)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 599
        },
        "id": "PU_54dtIkc7u",
        "outputId": "2a607e3b-20a4-4e80-97c9-f1d667f02d4e"
      },
      "id": "PU_54dtIkc7u",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "DatabaseError",
          "evalue": "Execution failed on sql '\nSELECT\n    i.Invoice,\n    i.BillingCountry,\n    i.Total,\n    ii.UnitPrice,\n    ii.Quantity\nFROM\n    invoices AS i\nINNER JOIN\n    invoice_items AS ii ON i.InvoiceId = ii.InvoiceId;\n': no such table: invoices",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mOperationalError\u001b[0m                          Traceback (most recent call last)",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pandas/io/sql.py\u001b[0m in \u001b[0;36mexecute\u001b[0;34m(self, sql, params)\u001b[0m\n\u001b[1;32m   2673\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2674\u001b[0;31m             \u001b[0mcur\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexecute\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msql\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2675\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mcur\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mOperationalError\u001b[0m: no such table: invoices",
            "\nThe above exception was the direct cause of the following exception:\n",
            "\u001b[0;31mDatabaseError\u001b[0m                             Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-107-1156391544>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Load the joined data into a Pandas DataFrame\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;31m#invoice_details_df = pd.read_sql_query(sql_query_invoices, conn)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0minvoice_item_df\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_sql_query\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msql_query_invoice_details\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pandas/io/sql.py\u001b[0m in \u001b[0;36mread_sql_query\u001b[0;34m(sql, con, index_col, coerce_float, params, parse_dates, chunksize, dtype, dtype_backend)\u001b[0m\n\u001b[1;32m    524\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    525\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mpandasSQL_builder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcon\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mpandas_sql\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 526\u001b[0;31m         return pandas_sql.read_query(\n\u001b[0m\u001b[1;32m    527\u001b[0m             \u001b[0msql\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    528\u001b[0m             \u001b[0mindex_col\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mindex_col\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pandas/io/sql.py\u001b[0m in \u001b[0;36mread_query\u001b[0;34m(self, sql, index_col, coerce_float, parse_dates, params, chunksize, dtype, dtype_backend)\u001b[0m\n\u001b[1;32m   2736\u001b[0m         \u001b[0mdtype_backend\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mDtypeBackend\u001b[0m \u001b[0;34m|\u001b[0m \u001b[0mLiteral\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"numpy\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"numpy\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2737\u001b[0m     ) -> DataFrame | Iterator[DataFrame]:\n\u001b[0;32m-> 2738\u001b[0;31m         \u001b[0mcursor\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexecute\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msql\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2739\u001b[0m         \u001b[0mcolumns\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mcol_desc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mcol_desc\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mcursor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdescription\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2740\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pandas/io/sql.py\u001b[0m in \u001b[0;36mexecute\u001b[0;34m(self, sql, params)\u001b[0m\n\u001b[1;32m   2684\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2685\u001b[0m             \u001b[0mex\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mDatabaseError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Execution failed on sql '{sql}': {exc}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2686\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mex\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mexc\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2687\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2688\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mstaticmethod\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mDatabaseError\u001b[0m: Execution failed on sql '\nSELECT\n    i.Invoice,\n    i.BillingCountry,\n    i.Total,\n    ii.UnitPrice,\n    ii.Quantity\nFROM\n    invoices AS i\nINNER JOIN\n    invoice_items AS ii ON i.InvoiceId = ii.InvoiceId;\n': no such table: invoices"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"### Head of Joined Invoice Details DataFrame:\")\n",
        "print(invoice_line_df.head())\n",
        "print(\"\\n\" + \"#\" * 50 + \"\\n\") # Separator for clarity\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 211
        },
        "id": "AOgN4cwqoU3u",
        "outputId": "5385cf02-d437-4030-8b9c-76a4299cb629"
      },
      "id": "AOgN4cwqoU3u",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "### Head of Joined Invoice Details DataFrame:\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'invoice_line_df' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-108-732878303>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"### Head of Joined Invoice Details DataFrame:\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minvoice_line_df\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhead\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"\\n\"\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m\"#\"\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;36m50\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m\"\\n\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# Separator for clarity\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'invoice_line_df' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Calculate the LineTotal for each invoice item\n",
        "invoice_details_df['LineTotal'] = invoice_details_df['UnitPrice'] * invoice_details_df['Quantity']\n",
        "\n",
        "print(\"### Head of Invoice Details with LineTotal:\")\n",
        "print(invoice_details_df.head())\n",
        "print(\"\\n\" + \"#\" * 50 + \"\\n\") # Separator for clarity\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 228
        },
        "id": "9WPW6IB1kxTz",
        "outputId": "1d832353-a67e-4710-a198-a766cba76498"
      },
      "id": "9WPW6IB1kxTz",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'invoice_details_df' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-103-1048076223>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Calculate the LineTotal for each invoice item\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0minvoice_details_df\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'LineTotal'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minvoice_details_df\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'UnitPrice'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0minvoice_details_df\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Quantity'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"### Head of Invoice Details with LineTotal:\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minvoice_details_df\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhead\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'invoice_details_df' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Find the BillingCountry with the highest total LineTotal\n",
        "total_revenue_by_country = invoice_details_df.groupby('BillingCountry')['LineTotal'].sum().reset_index()\n",
        "highest_revenue_country = total_revenue_by_country.loc[total_revenue_by_country['LineTotal'].idxmax()]\n",
        "\n",
        "print(\"### Country with the Highest Total Revenue (LineTotal):\")\n",
        "print(highest_revenue_country)\n",
        "print(\"\\n\" + \"#\" * 50 + \"\\n\") # Separator for clarity\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 245
        },
        "id": "7BuBXyvkqr7h",
        "outputId": "bf6fd3ae-4e5f-4452-e13d-53ecde3a8a9a"
      },
      "id": "7BuBXyvkqr7h",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'invoice_details_df' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-109-3213973997>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Find the BillingCountry with the highest total LineTotal\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mtotal_revenue_by_country\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minvoice_details_df\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgroupby\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'BillingCountry'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'LineTotal'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreset_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mhighest_revenue_country\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtotal_revenue_by_country\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtotal_revenue_by_country\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'LineTotal'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0midxmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"### Country with the Highest Total Revenue (LineTotal):\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'invoice_details_df' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Task 2.4 Solution: Analyze and Visualize Top Music Genres (Integrated Task)"
      ],
      "metadata": {
        "id": "eOZ7OcynMBaw"
      },
      "id": "eOZ7OcynMBaw"
    },
    {
      "cell_type": "code",
      "source": [
        "# Task 2.4 Solution: Analyze and Visualize Top Music Genres (Integrated Task)\n",
        "# SQL Query to calculate total revenue per genre\n",
        "sql_query_genre_revenue = \"\"\"\n",
        "SELECT\n",
        "    g.Name AS GenreName,\n",
        "    SUM(ii.UnitPrice * ii.Quantity) AS TotalRevenue\n",
        "FROM\n",
        "    genres AS g\n",
        "INNER JOIN\n",
        "    tracks AS t ON g.GenreId = t.GenreId\n",
        "INNER JOIN\n",
        "    invoice_items AS ii ON t.TrackId = ii.TrackId\n",
        "GROUP BY\n",
        "    g.Name\n",
        "ORDER BY\n",
        "    TotalRevenue DESC;\n",
        "\"\"\"\n",
        "\n",
        "# Load the results into a Pandas DataFrame\n",
        "genre_revenue_df = pd.read_sql_query(sql_query_genre_revenue, conn)\n",
        "\n",
        "print(\"### Total Revenue per Music Genre:\")\n",
        "print(genre_revenue_df.head(10)) # Display top 10 genres\n",
        "print(\"\\n\" + \"#\" * 50 + \"\\n\") # Separator for clarity\n",
        "\n",
        "# Create a bar chart for the top 5 genres by total revenue\n",
        "plt.figure(figsize=(12, 7))\n",
        "sns.barplot(x='TotalRevenue', y='GenreName', data=genre_revenue_df.head(5), palette='viridis')\n",
        "plt.title('Top 5 Music Genres by Total Revenue')\n",
        "plt.xlabel('Total Revenue ($)')\n",
        "plt.ylabel('Genre Name')\n",
        "plt.show()\n",
        "print(\"\\n\" + \"#\" * 50 + \"\\n\") # Separator for clarity\n",
        "\n",
        "# Close the database connection after all SQL tasks in Part 2.\n",
        "conn.close()\n",
        "print(\"Chinook database connection closed.\")\n"
      ],
      "metadata": {
        "id": "uk6VJp4UMAQ1"
      },
      "id": "uk6VJp4UMAQ1",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Part 3 Solutions: Data Merging and Advanced Visualization"
      ],
      "metadata": {
        "id": "jxilaaurMLdp"
      },
      "id": "jxilaaurMLdp"
    },
    {
      "cell_type": "markdown",
      "source": [
        "Task 3.1 Solution: Merging Datasets (Student Performance Data)"
      ],
      "metadata": {
        "id": "6pjTN1u7Mble"
      },
      "id": "6pjTN1u7Mble"
    },
    {
      "cell_type": "code",
      "source": [
        "# Task 3.1 Solution: Merging Datasets (Student Performance Data)\n",
        "# Load the student-mat.csv and student-por.csv datasets\n",
        "# Note: These CSVs are semicolon-separated, so specify the delimiter\n",
        "try:\n",
        "    student_mat_df = pd.read_csv(\"student-mat.csv\", sep=';')\n",
        "    student_por_df = pd.read_csv(\"student-por.csv\", sep=';')\n",
        "except FileNotFoundError:\n",
        "    print(\"Ensure 'student-mat.csv' and 'student-por.csv' are in the correct directory or downloaded via wget commands in setup.\")\n",
        "    # For a real lab, ensure these files are provided or easily accessible.\n",
        "    # To prevent errors during automated testing, we might want to create dummy files or raise a more specific error.\n",
        "    raise FileNotFoundError(\"Student performance CSVs not found. Please download them.\")\n",
        "\n",
        "print(\"### Head of Math Students DataFrame:\")\n",
        "print(student_mat_df.head())\n",
        "print(\"\\n\" + \"#\" * 50 + \"\\n\") # Separator for clarity\n",
        "\n",
        "print(\"### Head of Portuguese Students DataFrame:\")\n",
        "print(student_por_df.head())\n",
        "print(\"\\n\" + \"#\" * 50 + \"\\n\") # Separator for clarity\n",
        "\n",
        "# Define common columns for merging (excluding unique final grades G1, G2, G3 which differ per course)\n",
        "common_columns = [\n",
        "    'school', 'sex', 'age', 'address', 'famsize', 'Pstatus', 'Medu', 'Fedu',\n",
        "    'Mjob', 'Fjob', 'reason', 'guardian', 'traveltime', 'studytime', 'failures',\n",
        "    'schoolsup', 'famsup', 'paid', 'activities', 'nursery', 'higher', 'internet',\n",
        "    'romantic', 'famrel', 'freetime', 'goout', 'Dalc', 'Walc', 'health', 'absences'\n",
        "]\n",
        "\n",
        "# Merge the two DataFrames on common columns using an inner join\n",
        "# Suffixes are added to distinguish grades from different courses (G1_math, G3_por etc.)\n",
        "merged_students_df = pd.merge(student_mat_df, student_por_df, on=common_columns, how='inner',\n",
        "                              suffixes=('_math', '_por'))\n",
        "\n",
        "print(\"### Shape of Merged Students DataFrame (Common Students who took both courses):\")\n",
        "print(merged_students_df.shape)\n",
        "print(\"\\n\" + \"#\" * 50 + \"\\n\") # Separator for clarity\n",
        "\n",
        "print(\"### Head of Merged Students DataFrame (showing some common and specific columns):\\n\")\n",
        "# Display relevant columns to confirm merge and suffixes\n",
        "print(merged_students_df[['school', 'sex', 'age', 'G1_math', 'G2_math', 'G3_math', 'G1_por', 'G2_por', 'G3_por']].head())\n",
        "print(\"\\n\" + \"#\" * 50 + \"\\n\") # Separator for clarity\n",
        "\n",
        "# The 'merged_students_df' is now ready for use in Task 3.4.\n"
      ],
      "metadata": {
        "id": "jNI4G-mVMeUK"
      },
      "id": "jNI4G-mVMeUK",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Task 3.2 Solution: Univariate and Bivariate Visualization (Titanic Dataset - Using Cleaned Data from Part 1)**"
      ],
      "metadata": {
        "id": "E8GrM0EDMhHT"
      },
      "id": "E8GrM0EDMhHT"
    },
    {
      "cell_type": "code",
      "source": [
        "# Task 3.2 Solution: Univariate and Bivariate Visualization (Titanic Dataset - Using Cleaned Data from Part 1)\n",
        "# Set a style for Seaborn plots for better aesthetics\n",
        "sns.set_style('whitegrid')\n",
        "\n",
        "# Create a histogram of Age\n",
        "plt.figure(figsize=(10, 6))\n",
        "sns.histplot(titanic_df['Age'], bins=20, kde=True)\n",
        "plt.title('Distribution of Passenger Age on Titanic')\n",
        "plt.xlabel('Age')\n",
        "plt.ylabel('Count')\n",
        "plt.show()\n",
        "print(\"\\n\" + \"#\" * 50 + \"\\n\") # Separator for clarity\n",
        "\n",
        "# Create a bar chart showing the count of Survived\n",
        "plt.figure(figsize=(7, 5))\n",
        "sns.countplot(x='Survived', data=titanic_df, palette='pastel')\n",
        "plt.title('Survival Count on Titanic (0=No, 1=Yes)')\n",
        "plt.xlabel('Survived')\n",
        "plt.ylabel('Number of Passengers')\n",
        "plt.xticks(ticks=[0, 1], labels=['Did Not Survive', 'Survived'])\n",
        "plt.show()\n",
        "print(\"\\n\" + \"#\" * 50 + \"\\n\") # Separator for clarity\n",
        "\n",
        "# Create a box plot of Fare across different Pclass\n",
        "plt.figure(figsize=(10, 6))\n",
        "sns.boxplot(x='Pclass', y='Fare', data=titanic_df, palette='viridis')\n",
        "plt.title('Fare Distribution Across Passenger Classes')\n",
        "plt.xlabel('Passenger Class')\n",
        "plt.ylabel('Fare')\n",
        "plt.show()\n",
        "print(\"\\n\" + \"#\" * 50 + \"\\n\") # Separator for clarity\n",
        "\n",
        "# Create a count plot to visualize the relationship between Sex, Survived, and Pclass\n",
        "# Use a catplot to easily facet by 'Sex'\n",
        "g = sns.catplot(x='Pclass', hue='Survived', col='Sex', data=titanic_df, kind='count', height=5, aspect=1.2, palette='Set2')\n",
        "g.set_axis_labels(\"Passenger Class\", \"Number of Passengers\")\n",
        "g.set_titles(\"Sex: {col_name}\")\n",
        "plt.suptitle('Survival Count by Passenger Class and Sex', y=1.02) # Adjust suptitle position for catplot\n",
        "plt.show()\n",
        "print(\"\\n\" + \"#\" * 50 + \"\\n\") # Separator for clarity\n"
      ],
      "metadata": {
        "id": "5ljq8pq0MHbR"
      },
      "id": "5ljq8pq0MHbR",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "j-q2uKveMr93"
      },
      "id": "j-q2uKveMr93",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Task 3.3 Solution: Churn Analysis with Engineered Feature (Telco Customer Churn - Using Engineered Feature from Part 1)"
      ],
      "metadata": {
        "id": "XYjSDEPqMx2G"
      },
      "id": "XYjSDEPqMx2G"
    },
    {
      "cell_type": "code",
      "source": [
        "# Task 3.3 Solution: Churn Analysis with Engineered Feature (Telco Customer Churn - Using Engineered Feature from Part 1)\n",
        "# The 'telco_df' should already contain the 'HasInternetService' column from Task 1.3.\n",
        "\n",
        "plt.figure(figsize=(8, 6))\n",
        "sns.countplot(x='HasInternetService', hue='Churn', data=telco_df, palette='coolwarm')\n",
        "plt.title('Churn Rate by Internet Service Availability')\n",
        "plt.xlabel('Has Internet Service (0=No, 1=Yes)')\n",
        "plt.ylabel('Number of Customers')\n",
        "plt.xticks(ticks=[0, 1], labels=['No Internet Service', 'Has Internet Service'])\n",
        "plt.legend(title='Churn', labels=['No Churn', 'Churn'])\n",
        "plt.show()\n",
        "print(\"\\n\" + \"#\" * 50 + \"\\n\") # Separator for clarity\n",
        "\n",
        "# Optionally, calculate churn percentages for deeper insights\n",
        "churn_by_internet = telco_df.groupby('HasInternetService')['Churn'].value_counts(normalize=True).unstack()\n",
        "print(\"### Churn Percentage by Internet Service:\")\n",
        "print(churn_by_internet)\n",
        "print(\"\\n\" + \"#\" * 50 + \"\\n\") # Separator for clarity\n"
      ],
      "metadata": {
        "id": "ZnKs1Uf0M7T8"
      },
      "id": "ZnKs1Uf0M7T8",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Task 3.4 Solution: Comparative Analysis of Student Performance (Integrated Task)"
      ],
      "metadata": {
        "id": "DkfxoUIaM-bj"
      },
      "id": "DkfxoUIaM-bj"
    },
    {
      "cell_type": "code",
      "source": [
        "# Task 3.4 Solution: Comparative Analysis of Student Performance (Integrated Task)\n",
        "# The 'merged_students_df' should already be created in Task 3.1.\n",
        "\n",
        "# Calculate the average final grade (G3) for math and Portuguese courses\n",
        "avg_g3_math = merged_students_df['G3_math'].mean()\n",
        "avg_g3_por = merged_students_df['G3_por'].mean()\n",
        "\n",
        "print(f\"Average final grade in Mathematics (G3_math): {avg_g3_math:.2f}\")\n",
        "print(f\"Average final grade in Portuguese (G3_por): {avg_g3_por:.2f}\")\n",
        "print(\"\\n\" + \"#\" * 50 + \"\\n\") # Separator for clarity\n",
        "\n",
        "# Prepare data for plotting\n",
        "# Create a DataFrame suitable for comparison\n",
        "grade_comparison_df = pd.DataFrame({\n",
        "    'Course': ['Mathematics', 'Portuguese'],\n",
        "    'Average G3': [avg_g3_math, avg_g3_por]\n",
        "})\n",
        "\n",
        "# Create a bar chart to compare average final grades\n",
        "plt.figure(figsize=(8, 6))\n",
        "sns.barplot(x='Course', y='Average G3', data=grade_comparison_df, palette='Paired')\n",
        "plt.title('Comparison of Average Final Grades (G3) for Students in Both Courses')\n",
        "plt.xlabel('Course')\n",
        "plt.ylabel('Average Final Grade (G3)')\n",
        "plt.ylim(0, 20) # Grades are typically 0-20\n",
        "plt.show()\n",
        "print(\"\\n\" + \"#\" * 50 + \"\\n\") # Separator for clarity\n",
        "\n",
        "# Optional: Box plot to compare grade distributions (more detailed than just average)\n",
        "plt.figure(figsize=(10, 6))\n",
        "sns.boxplot(data=merged_students_df[['G3_math', 'G3_por']], palette='light:b')\n",
        "plt.title('Distribution of Final Grades (G3) for Students in Both Courses')\n",
        "plt.xlabel('Course')\n",
        "plt.ylabel('Final Grade (G3)')\n",
        "plt.xticks(ticks=[0, 1], labels=['Mathematics (G3)', 'Portuguese (G3)'])\n",
        "plt.show()\n",
        "print(\"\\n\" + \"#\" * 50 + \"\\n\") # Separator for clarity\n"
      ],
      "metadata": {
        "id": "-PFTdJSbNDPX"
      },
      "id": "-PFTdJSbNDPX",
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "language_info": {
      "name": "python"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}